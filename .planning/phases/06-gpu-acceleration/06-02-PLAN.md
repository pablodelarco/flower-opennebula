---
phase: 06-gpu-acceleration
plan: 02
type: execute
wave: 2
depends_on: ["06-01"]
files_modified:
  - spec/10-gpu-passthrough.md
  - spec/03-contextualization-reference.md
  - spec/02-supernode-appliance.md
autonomous: true

must_haves:
  truths:
    - "A reader can run validation scripts to verify the GPU stack is correctly configured"
    - "A reader can find FL_GPU_* variables in the contextualization reference with full USER_INPUT definitions"
    - "A reader can understand the SuperNode GPU detection step in the boot sequence"
  artifacts:
    - path: "spec/10-gpu-passthrough.md"
      provides: "GPU validation script specifications"
      contains: ["validate-gpu.sh", "validate-host-gpu.sh"]
    - path: "spec/03-contextualization-reference.md"
      provides: "FL_GPU_* contextualization variables"
      contains: ["FL_GPU_ENABLED", "FL_CUDA_VISIBLE_DEVICES", "FL_GPU_MEMORY_FRACTION"]
    - path: "spec/02-supernode-appliance.md"
      provides: "GPU detection in boot sequence"
      contains: ["GPU detection", "FL_GPU_ENABLED"]
  key_links:
    - from: "spec/03-contextualization-reference.md"
      to: "spec/10-gpu-passthrough.md"
      via: "FL_GPU_* variables reference GPU passthrough spec for implementation details"
      pattern: "spec/10-gpu-passthrough"
---

<objective>
Add GPU validation scripts and integrate GPU configuration into existing spec documents

Purpose: Complete Phase 6 by adding validation script specifications and integrating GPU contextualization variables into the existing reference documents. This ensures the GPU stack is verifiable and the new variables are discoverable in the canonical contextualization reference.

Output: Validation script specs added to spec/10-gpu-passthrough.md, FL_GPU_* variables added to spec/03-contextualization-reference.md, GPU detection step added to spec/02-supernode-appliance.md
</objective>

<execution_context>
@/home/pablo/.claude/get-shit-done/workflows/execute-plan.md
@/home/pablo/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/06-gpu-acceleration/06-RESEARCH.md

# Prior plan output
@spec/10-gpu-passthrough.md

# Files to update
@spec/03-contextualization-reference.md
@spec/02-supernode-appliance.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add validation script specifications to GPU spec</name>
  <files>spec/10-gpu-passthrough.md</files>
  <action>
Append validation script specifications to spec/10-gpu-passthrough.md:

**Section: Validation Scripts**

1. **Host-Level Validation Script (validate-host-gpu.sh)**
   - Purpose: Run on OpenNebula KVM host to verify GPU passthrough prerequisites
   - Checks (from research):
     1. IOMMU enabled in kernel (`grep intel_iommu=on /proc/cmdline`)
     2. IOMMU groups exist (`ls /sys/kernel/iommu_groups/`)
     3. vfio-pci module loaded (`lsmod | grep vfio_pci`)
     4. NVIDIA GPUs bound to vfio-pci driver (`lspci -Dnns <addr> -k`)
     5. VFIO udev rules configured
     6. OpenNebula PCI filter configured for NVIDIA (10de)
   - Output: PASS/FAIL with specific FIX instructions for each failed check
   - Include full script from 06-RESEARCH.md (validate-host-gpu.sh)
   - Location: Document as `/opt/flower/scripts/validate-host-gpu.sh` for infrastructure operators

2. **VM-Level Validation Script (validate-gpu.sh)**
   - Purpose: Run inside VM to verify GPU is accessible to containers
   - Checks (from research):
     1. NVIDIA kernel module loaded (`lsmod | grep nvidia`)
     2. nvidia-smi responds and reports GPU name/memory
     3. NVIDIA Container Toolkit configured (`grep nvidia /etc/docker/daemon.json`)
     4. Docker containers can access GPU (`docker run --rm --gpus all nvidia/cuda:12.0-base nvidia-smi`)
     5. CUDA version information
   - Output: PASS/FAIL with error count
   - Include full script from 06-RESEARCH.md (validate-gpu.sh)
   - Location: `/opt/flower/scripts/validate-gpu.sh` (pre-installed in GPU-enabled QCOW2)

3. **Validation Integration Points**
   - Host script: Run by infrastructure operator before deploying GPU-enabled VMs
   - VM script: Can be run manually via SSH or as part of boot sequence health check
   - Boot sequence integration: If FL_GPU_ENABLED=YES and validate-gpu.sh fails, log WARNING but continue with CPU fallback

4. **Validation Troubleshooting Table**
   | Symptom | Likely Cause | Fix |
   |---------|--------------|-----|
   | "No IOMMU groups found" | IOMMU disabled in BIOS | Enable Intel VT-d or AMD IOMMU in BIOS |
   | "nvidia module not loaded" | Driver not installed | apt install nvidia-driver-545 |
   | "could not select device driver" | Container Toolkit not configured | nvidia-ctk runtime configure --runtime=docker |
   | GPU shows in host but not VM | vfio-pci not bound | driverctl set-override <addr> vfio-pci |
  </action>
  <verify>
    - spec/10-gpu-passthrough.md contains Validation Scripts section
    - Contains validate-host-gpu.sh script specification
    - Contains validate-gpu.sh script specification
    - Contains Validation Troubleshooting Table
  </verify>
  <done>
    Validation script specifications added to GPU passthrough spec with full scripts and troubleshooting table
  </done>
</task>

<task type="auto">
  <name>Task 2: Add FL_GPU_* variables to contextualization reference</name>
  <files>spec/03-contextualization-reference.md</files>
  <action>
Update spec/03-contextualization-reference.md to add GPU contextualization variables:

1. **Find the SuperNode Variables section** (should be after SuperLink variables)

2. **Add GPU Configuration subsection** with these variables:

| Variable | Type | Required | Default | Description |
|----------|------|----------|---------|-------------|
| FL_GPU_ENABLED | string (YES/NO) | No | NO | Enable NVIDIA GPU passthrough. When YES, adds --gpus flag to docker run. Requires GPU-enabled VM template. |
| FL_CUDA_VISIBLE_DEVICES | string | No | all | Comma-separated list of GPU device IDs visible to container (e.g., "0", "0,1"). Only effective when FL_GPU_ENABLED=YES. |
| FL_GPU_MEMORY_FRACTION | float | No | 0.8 | GPU memory fraction for PyTorch (0.0-1.0). Soft limit -- actual usage may exceed. Only effective when ML_FRAMEWORK=pytorch and FL_GPU_ENABLED=YES. |

3. **Add USER_INPUT definitions** for each variable:

```
USER_INPUT = [
    GPU = "O|boolean|Enable GPU passthrough (requires GPU-enabled VM template)| |NO",
    CUDA_DEVICES = "O|text|GPU device IDs visible to container (e.g., 0 or 0,1)| |all",
    GPU_MEMORY_FRACTION = "O|number|GPU memory fraction for PyTorch (0.0-1.0)| |0.8"
]
```

4. **Add validation rules:**
   - FL_GPU_ENABLED: Must be YES or NO (case-insensitive)
   - FL_CUDA_VISIBLE_DEVICES: If not "all", must be comma-separated integers (0, 0,1, 0,1,2)
   - FL_GPU_MEMORY_FRACTION: Must be float between 0.0 and 1.0

5. **Add cross-reference note:**
   "See spec/10-gpu-passthrough.md for complete GPU stack configuration and validation procedures."

6. **Update variable count** in the document header if present
  </action>
  <verify>
    - spec/03-contextualization-reference.md contains FL_GPU_ENABLED variable
    - Contains FL_CUDA_VISIBLE_DEVICES variable
    - Contains FL_GPU_MEMORY_FRACTION variable
    - Contains USER_INPUT definitions for GPU variables
    - Contains cross-reference to spec/10-gpu-passthrough.md
  </verify>
  <done>
    FL_GPU_* contextualization variables added to reference document with full USER_INPUT definitions and validation rules
  </done>
</task>

<task type="auto">
  <name>Task 3: Add GPU detection step to SuperNode boot sequence</name>
  <files>spec/02-supernode-appliance.md</files>
  <action>
Update spec/02-supernode-appliance.md to add GPU detection in boot sequence:

1. **Find the Boot Sequence section** (should list 13 steps currently)

2. **Insert new step after Step 8 (Discovery) and before Step 9 (Start Container)**
   This becomes Step 9, and subsequent steps renumber.

   **Step 9: GPU Detection**

   **WHAT:** Check GPU availability when FL_GPU_ENABLED=YES

   **WHY:** Determine container launch flags and enable graceful CPU fallback

   **ACTIONS:**
   1. If FL_GPU_ENABLED != YES, skip to Step 10
   2. Check if NVIDIA driver is loaded: `lsmod | grep -q nvidia`
   3. Check if nvidia-smi responds: `nvidia-smi > /dev/null 2>&1`
   4. If both checks pass, set `DOCKER_GPU_FLAGS="--gpus all"`
   5. If FL_CUDA_VISIBLE_DEVICES is set and not "all", add `-e CUDA_VISIBLE_DEVICES=${FL_CUDA_VISIBLE_DEVICES}`
   6. If checks fail, log WARNING: "GPU requested but not available, falling back to CPU"
   7. Optionally run /opt/flower/scripts/validate-gpu.sh for detailed diagnostics

   **FAILURE:** GPU not available
   - Severity: WARNING (not FATAL)
   - Boot continues: YES
   - Recovery: Training proceeds on CPU with degraded performance
   - OneGate: FL_GPU_AVAILABLE=NO published (if OneGate reachable)

3. **Update docker run command section** to include GPU flags:
   - Add conditional `${DOCKER_GPU_FLAGS}` to docker run command
   - Document that DOCKER_GPU_FLAGS is empty string if GPU not enabled/available

4. **Renumber subsequent steps** (old Step 9 becomes Step 10, etc.)

5. **Update step count** in boot sequence overview (13 steps -> 14 steps)

6. **Add cross-reference:** "See spec/10-gpu-passthrough.md for GPU stack configuration requirements"
  </action>
  <verify>
    - spec/02-supernode-appliance.md contains GPU Detection step
    - Boot sequence now shows 14 steps (or updated count)
    - Contains DOCKER_GPU_FLAGS variable usage
    - GPU unavailable is documented as WARNING not FATAL
    - Contains cross-reference to spec/10-gpu-passthrough.md
  </verify>
  <done>
    SuperNode boot sequence updated with GPU detection step, graceful fallback, and cross-reference to GPU spec
  </done>
</task>

</tasks>

<verification>
Phase 6 Plan 02 verification:

1. **Validation scripts:** Both host-level and VM-level scripts specified with full code
2. **Troubleshooting:** Table mapping symptoms to causes and fixes
3. **Contextualization:** FL_GPU_* variables in reference with USER_INPUT definitions
4. **Boot sequence:** GPU detection step added to SuperNode with CPU fallback
5. **Cross-references:** All updated documents link to spec/10-gpu-passthrough.md
</verification>

<success_criteria>
- spec/10-gpu-passthrough.md contains validation script specifications with full scripts
- spec/03-contextualization-reference.md contains FL_GPU_* variables with USER_INPUT definitions
- spec/02-supernode-appliance.md contains GPU detection step in boot sequence
- All cross-references between specs are in place
- GPU unavailable path is WARNING, not FATAL
</success_criteria>

<output>
After completion, create `.planning/phases/06-gpu-acceleration/06-02-SUMMARY.md` using the summary template
</output>
