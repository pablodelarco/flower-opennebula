---
name: Flower SuperNode 1.25.0
version: 1.25.0-1.0.0
publisher: OpenNebula Systems
description: |-
  VM template for the [Flower](https://flower.ai/) SuperNode appliance
  (federated learning client).

  Deploys a SuperNode VM that trains locally on private data and sends
  only model weights to the SuperLink coordinator. Includes PyTorch,
  TensorFlow, and scikit-learn pre-baked -- select the framework at
  deployment time via `ONEAPP_FL_FRAMEWORK`. SuperNodes auto-discover
  the SuperLink via OneGate and reconnect automatically on failure.

  Part of the **Flower Federated Learning** appliance set.
  Imported automatically when you export the
  [Service Flower FL 1.25.0](8b437ffe-7b90-4dc0-a453-f0646b11ab09) service.

  Requires
  [OneGate](https://docs.opennebula.io/stable/management_and_operations/multivm_service_management/onegate_usage.html)
  for SuperLink auto-discovery.
short_description: Flower SuperNode VM template (FL training client, multi-framework)
tags:
- flower
- federated-learning
- supernode
- ubuntu
- service
type: VMTEMPLATE
format: qcow2
creation_time: 1770822863
os-id: Ubuntu
os-release: '24.04 LTS'
os-arch: x86_64
hypervisor: KVM
opennebula_version: 6.8, 6.10, 7.0
opennebula_template:
  context:
    token: 'YES'
    network: 'YES'
    report_ready: 'YES'
    ssh_public_key: "$USER[SSH_PUBLIC_KEY]"
    oneapp_flower_version: "$ONEAPP_FLOWER_VERSION"
    oneapp_fl_tls_enabled: "$ONEAPP_FL_TLS_ENABLED"
    oneapp_fl_log_level: "$ONEAPP_FL_LOG_LEVEL"
    oneapp_fl_log_format: "$ONEAPP_FL_LOG_FORMAT"
    oneapp_fl_framework: "$ONEAPP_FL_FRAMEWORK"
    oneapp_fl_node_config: "$ONEAPP_FL_NODE_CONFIG"
    oneapp_fl_gpu_enabled: "$ONEAPP_FL_GPU_ENABLED"
    oneapp_fl_cuda_visible_devices: "$ONEAPP_FL_CUDA_VISIBLE_DEVICES"
    oneapp_fl_gpu_memory_fraction: "$ONEAPP_FL_GPU_MEMORY_FRACTION"
    oneapp_fl_dcgm_enabled: "$ONEAPP_FL_DCGM_ENABLED"
  cpu: '2'
  memory: '4096'
  graphics:
    listen: 0.0.0.0
    type: vnc
  inputs_order: >-
    ONEAPP_FL_FRAMEWORK,ONEAPP_FL_GPU_ENABLED,ONEAPP_FL_NODE_CONFIG,ONEAPP_FL_LOG_LEVEL
  os:
    arch: x86_64
  user_inputs:
    oneapp_flower_version: "O|text|Flower Docker image version tag||1.25.0"
    oneapp_fl_framework: "O|list|ML framework for training|pytorch,tensorflow,sklearn|pytorch"
    oneapp_fl_tls_enabled: "O|boolean|Enable TLS encryption||YES"
    oneapp_fl_log_level: "O|list|Log verbosity|DEBUG,INFO,WARNING,ERROR|INFO"
    oneapp_fl_log_format: "O|list|Log output format|text,json|text"
    oneapp_fl_node_config: "O|text|Space-separated key=value node config||"
    oneapp_fl_gpu_enabled: "O|boolean|Enable GPU passthrough||NO"
    oneapp_fl_cuda_visible_devices: "O|text|CUDA devices (all or comma-separated IDs)||all"
    oneapp_fl_gpu_memory_fraction: "O|number-float|GPU memory fraction per client||0.8"
    oneapp_fl_dcgm_enabled: "O|boolean|Enable DCGM GPU metrics exporter||NO"
logo: flower.png
disks:
- "Flower SuperNode 1.25.0 OS disk"
images: []
